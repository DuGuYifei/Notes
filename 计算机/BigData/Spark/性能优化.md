# 性能优化

性能优化
我们已经讨论了Spark集群和提高导入性能的方法。现在让我们看看如何改善Spark任务的整体性能。

解释Spark执行计划
要了解Spark的性能影响，你必须能够看到它在幕后的操作。最简单的方法是在DataFrame上使用.explain()函数。这个例子是从之前的练习中提取的，仅请求单个列并对其运行distinct操作。结果是生成DataFrame结果的估计计划。现在不用担心计划的具体细节，只需要记住在需要时如何查看它。

什么是Shuffling（洗牌）？
Spark将数据分布在集群的各个节点上。这样做的副作用就是洗牌。洗牌是根据需要将数据片段移动到各个工作节点的过程，以完成某些任务。洗牌是有用的，并且隐藏了用户的整体复杂性（用户不需要知道哪个节点有什么数据）。尽管如此，如果少数节点需要所有数据，洗牌的完成所需的数据传输可能会很慢。洗牌降低了集群的整体吞吐量，因为工作节点必须花时间等待数据传输。这限制了剩余任务中可用的工作节点数量。洗牌通常是必要的组成部分，但尽量尽量减少洗牌操作会有所帮助。

如何限制洗牌？
完全消除洗牌操作可能有些棘手，但有几个方法可以限制它。DataFrame的`.repartition()`函数接受一个参数，即所请求的分区数。我们在之前的章节中使用过它来说明分区对monotonically_increasing_id()函数的影响。重新分区需要在节点和进程之间进行完整的数据洗牌，代价非常高。如果需要减少分区数，可以使用`.coalesce()`函数代替。它接受一个比当前分区数小的分区数，并在不需要进行完整数据洗牌的情况下合并数据。注意：调用`.coalesce()`(合并)时，使用较大的分区数实际上不会产生任何效果。`.join()`函数是Spark的一个强大功能。不加选择地调用`.join()`通常会导致洗牌操作，增加集群负载并降低处理速度。为了避免在连接Spark DataFrames时的一些洗牌操作，可以使用`.broadcast()`函数。稍后我们将对此进行更详细的讨论。最后，关于数据清理操作的一个重要提示是记住针对重要的方面进行优化。你的初始代码的速度可能是可以接



1. `.coalesce()`（合并） 是一个减少分区的函数，而 `.repartition()` 是一个增加分区的函数。
2. `.broadcast` 是一个用于连接的函数，它可以减少洗牌操作。
3. `.explain()` 是一个用于查看Spark执行计划的函数。

## broadcast和join
```python
# Join the flights_df and airports_df DataFrames
normal_df = flights_df.join(airports_df, flights_df["Destination Airport"] == airports_df["IATA"])

# Show the query plan
normal_df.explain()
```

```python
# Import the broadcast method from pyspark.sql.functions
from pyspark.sql.functions import broadcast

# Join the flights_df and airports_df DataFrames using broadcasting
broadcast_df = flights_df.join(broadcast(airports_df), flights_df["Destination Airport"] == airports_df["IATA"])

# Show the query plan and compare against the original
broadcast_df.explain()
```