# TransformerModel
简介
--

1.  利用残差连接 residual connections 和归一化层 normalization layers
2.  自注意力机制模块，在**解码**使用掩码注意力机制masked attention mechanism (自注意力机制的特殊情况)
3.  语言建模（文本生成），机器翻译

[Transformer](#root/4gR9tOcpZ39O/Cupj1DmhZ2ex/XwLj1JOw1mia/VR71E0hGi84Q/zAeAXnoFzYI7) 快速学习