# Lecture 12 - Advanced topics

## GNN

Graph Neural Networks

* Node: a concept
* Edge: a connection between concepts

æ¯”å¦‚ï¼š3D mesh classification

## Generative Models

### AEå’ŒVAE

[AE VAE](./Lecture08-è¡¥å……Exercise8-TransferLearningAndAutoencoders.md)

### GAN

Generative Adversarial Networks

![alt text](_attachments/Lecture12-AdvancedTopics/image.png)

1. ç”¨å¸¦real fakeçš„labelçš„å›¾ç‰‡
2. train discriminatoræ¥åŒºåˆ†realå’Œfake
3. è¿™é‡Œçš„lantant random variableæ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå¦‚å‡åŒ€åˆ†å¸ƒæˆ–æ­£æ€åˆ†å¸ƒï¼‰ä¸­éšæœºé‡‡æ ·å¾—åˆ°çš„æ½œåœ¨å‘é‡ã€‚è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒæ˜¯æ‰‹åŠ¨è®¾å®šçš„ï¼Œä¸æ•°æ®æ— å…³ï¼Œå…¶ç›®çš„æ˜¯ä¸ºç”Ÿæˆå™¨æä¾›ä¸€ä¸ªéšæœºå™ªå£°çš„æºï¼Œä»è€Œä½¿ç”Ÿæˆå™¨èƒ½å¤Ÿå­¦ä¹ å¦‚ä½•å°†è¿™äº›å™ªå£°æ˜ å°„åˆ°æ•°æ®åˆ†å¸ƒä¸Šã€‚

## Diffusion

### Diffusion process

* Gradually add noise to input image ğ‘¥0 in a series of ğ‘‡ time steps
* Neural network trained to recover original data

![alt text](_attachments/Lecture12-AdvancedTopics/image-1.png)

#### Forward diffusion

* Markov chain of ğ‘‡ steps
  * each step depends only on previous
* Add noise to x_0 sampled from real distribution

![alt text](_attachments/Lecture12-AdvancedTopics/image-2.png)

#### Reverse Diffusion

* ğ‘¥_{ğ‘‡â†’âˆ} becomes a Gaussian distribution
* Reverse distribution
  * Sample ğ‘¥_ğ‘‡~ğ’©(ğŸ,ğˆ) and run reverse process
  * Generates a novel data point from original distribution

### Difusion Model Architecture

* Input and output dimensions must match
* Highly flexible to architecture design
* Commonly implemented with U-Net architectures